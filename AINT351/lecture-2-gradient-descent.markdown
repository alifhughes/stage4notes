# AINT351 - Gradient descent
> Date: 03-10-16

# Gradient Descent

How do we adjust the weights to see how it best works for our formula
How do we change it and see that it makes it better or worse
- Whats the best way to adjust things

### Gradient descent
- How can we get to the top of a hill?
    - We follow the gradient
- How do we know we are at a peak
    - It goes down on both sides
- Same is true for mathematical functions

### Gradient of a curve

- Gradient is the slope of a curve or surface
- Going up a hill it is +ve
- Going down a hill it is -ve
- At maxima it is zero

### Gradient of a straight line
- Gradient = Change in Y \ Change in X

### Iterative gradient decent
- Estimate a varience
    - move in that direction
- keep doing so
- until you reach values not changing much
    - reached convergence

### Least squares fitting
- Linear regression
- We want to fit a straight line to data measurements
- Equation for straight line in a single dimension is:
        Yi = MXi + C
- bit in brackets is predicted

##### To Do:
- look at second slide of least squares onwards until matlab matrices
